1.安装tensorflow（cpu版本就可以了）
2.运行backend.py

已有的文件及其用途：
backend是主程序，其他所有的.py文件都是我从自己的另外一个项目里扒出来的，所以里面有很多在本项目中用不到的代码……
validation.tfrecords是CIFAR10数据集
origin_vfs.npy是模型文件，里面是一个dictionary，保存了模型所有的weights。
d3project这个文件夹里面是我这门课的小作业……assignment1跟这个项目有点关系，可以参考一下。它是用别人实现的一个js版本的Louvain算法根据一个256*256的矩阵（filters256.json）对256个点进行聚类。

用法：
backend运行中，会在本目录下生成并更新png和csv文件（survey_example_{}.csv），最多保存10个。
csv的第一行，是所属类别（0到9共10类）
后面13行，每一行对应一层，每个数对应这一层的一个filter的输出的平均值
第1-2行应该每行64个数，3-4行每行128个数，5-7行每行256个数，8-13行每行512个数
13个corr_layer_{}.csv是每层各个filter的相关系数（corr）。例如，第13层有512个filter，那么corr_layer_12.csv里应该是一个512*512的矩阵。在程序运行过程中，随着feed的图片越来越多，这13个文件会不断地变化，并逐渐稳定。所以聚类也是一个不断变化并趋于稳定的过程。
在backend.py里面有一行corr_array = np.exp(20*corr_array)，是对相关系数进行映射，这个公式没有什么道理，完全就是因为试验出来的聚类效果好看而已……要不然矩阵里都是-1到1的数，在这个算法里聚类效果不好看。

迭代一的功能：
功能一（参见ppt）。上下布局还是左右布局？左边（或上边？）图刷刷刷刷的进，右边（或下边）产生对应变化（小方块对应filter，例如第一层应该64个小方块，最后一层应该512个小方块，怎么摆放好看还是个问题……），最后输出每个类的概率和最终判断的分类结果。
功能二：我之前写的assignment1只是关注一个层，即一个矩阵文件（filters256.json）。迭代一需要能在不同的层之间进行切换，以及动态的聚类的过程更好看。这个动态很重要，因为这个算法本身就能展示聚类过程的更新过程，而且这些矩阵（corr_layer_{}.csv）还是随时间变化的（改变backend.py中的CORR_SAVE_EVERY_STEP来调整更新频率）

迭代二的功能：
在功能一里，点一个filter（一个方块），显示热力图和反卷积得出的特征
在功能二里，随着图片feed进去，对应filter（圆点）根据其输出值产生亮度变化，以印证聚类的合理性（同一类别的图片产生的亮度变化应该具有空间上的相似性）
